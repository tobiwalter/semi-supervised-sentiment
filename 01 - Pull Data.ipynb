{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import requests\n",
    "    import tweepy\n",
    "except:\n",
    "    !pip install requests\n",
    "    !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urlparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ef59129ca799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0murlparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_qs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#python2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'urlparse'"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "#import logging\n",
    "import errno\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from urlparse import parse_qs\n",
    "try:\n",
    "    #python2\n",
    "    from urllib import urlencode\n",
    "except ImportError:\n",
    "    #python3\n",
    "    from urllib.parse import urlencode\n",
    "try:\n",
    "    #python2\n",
    "    from urlparse import urlparse, urlunparse\n",
    "except ImportError:\n",
    "    #python3\n",
    "    from urllib.parse import urlparse, urlunparse\n",
    "from pprint import pprint\n",
    "\n",
    "#from misc import helper\n",
    "#from misc.config import config\n",
    "import tweepy\n",
    "import codecs\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "#logging.basicConfig(level=logging.INFO,\n",
    "#                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check authentication and build API object for calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"bobVxy9mbwl3C1gnoQ61higKj\"\n",
    "CONSUMER_SECRET = \"6S57qgv3xiM3kuS7WIfeQTODbqKc6fHjWxpL9xLyvFwjLTMjEK\"\n",
    "auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "if not api:\n",
    "    print(\"no authentication\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"API has been set up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform API pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generate the different requests for the topics and emoticons\n",
    "Result will be a request query for every combination of topic with emoticon(positive/negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"Series\":[\n",
    "        \"Breaking Bad\",\n",
    "        \"Stranger Things\",\n",
    "        \"Two and a half men\",\n",
    "        \"The big bang theory\",\n",
    "        \"Game of Thrones\",\n",
    "        \"Better Call Saul\",\n",
    "        \"Sherlock\",\n",
    "        \"True Detective\",\n",
    "        \"The Walking Dead\",\n",
    "        \"House of Cards\",\n",
    "        \"How I met your Mother\",\n",
    "        \"Black Mirror\",\n",
    "        \"Lost in Space\",\n",
    "        \"Riverdale\",\n",
    "        \"House of Cards\",\n",
    "        \"Westworld\",\n",
    "        \"Suits\",\n",
    "        \"Supernatural\",\n",
    "        \"Prison Break\",\n",
    "        \"Homeland\",\n",
    "        \"Dr. House\",\n",
    "        \"Law and Order\",\n",
    "        \"TV Show\",\n",
    "        \"Netflix\"\n",
    "    ],\n",
    "    \"Movies\":[\n",
    "        \"Avengers\",\n",
    "        \"Marvel\",\n",
    "        \"Fifty Shades of Grey\",\n",
    "        \"A Quiet Place\",\n",
    "        \"Anihilation\",\n",
    "        \"Lord of the Rings\",\n",
    "        \"Star Wars\",\n",
    "        \"Infinity War\",\n",
    "        \"Spider Man\",\n",
    "        \"Guardians of the Galaxy\",\n",
    "        \"Black Panther\",\n",
    "        \"Iron Man\",\n",
    "        \"Deadpool\",\n",
    "        \"Red Sparrow\",\n",
    "        \"Batman\"\n",
    "    ],\n",
    "    \"Technology\":[\n",
    "        \"iPhone\",\n",
    "        \"iPad\",\n",
    "        \"Android\",\n",
    "        \"Apple\",\n",
    "        \"Samsung\",\n",
    "        \"Huawei\",\n",
    "        \"Alexa\",\n",
    "        \"Siri\",\n",
    "        \"GoogleHome\",\n",
    "        \"Dell\",\n",
    "        \"HP\",\n",
    "        \"Siemens\",\n",
    "        \"Google\",\n",
    "        \"Microsoft\",\n",
    "        \"Playstation\"\n",
    "    ],\n",
    "    \"FastFood\":[\n",
    "        \"McDonalds\",\n",
    "        \"Burger King\",\n",
    "        \"Pizza Hut\",\n",
    "        \"Dunkin Donuts\",\n",
    "        \"KFC\",\n",
    "        \"Starbucks\",\n",
    "        \"Subway\",\n",
    "        \"Taco Bell\",\n",
    "        \"Wendys\",\n",
    "        \"Dominos\",\n",
    "        \"Burger\",\n",
    "        \"Pizza\",\n",
    "        \"Pasta\",\n",
    "        \"Foodporn\",\n",
    "        \"bbq\",\n",
    "        \"barbecue\",\n",
    "        \"breakfast\",\n",
    "        \"dinner\",\n",
    "        \"lunch\",\n",
    "        \"brunch\",\n",
    "        \"Food\"\n",
    "    ],\n",
    "    \"Musician\":[\n",
    "        \"Drake\",\n",
    "        \"Dua Lipa\",\n",
    "        \"TheWeeknd\",\n",
    "        \"Kendrick Lamar\",\n",
    "        \"Nicki Minaj\",\n",
    "    #    #\"Avicii\",\n",
    "        \"Justin Bieber\",\n",
    "        \"Lady Gaga\",\n",
    "        \"Katy Perry\",\n",
    "        \"Rihanna\",\n",
    "        \"Taylor Swift\",\n",
    "        \"Bruno Mars\",\n",
    "        \"Adele\",\n",
    "        \"Wiz Khalifa\",\n",
    "        \"Justin Timberlake\",\n",
    "        \"Rock\",\n",
    "        \"Pop\",\n",
    "        \"Hiphop\",\n",
    "        \"Rap\",\n",
    "        \"Jazz\",\n",
    "        \"Techno\",\n",
    "        \"Coachella\",\n",
    "        \"Reggae\",\n",
    "        \"Blues\",\n",
    "        \"Punk\"\n",
    "    ],\n",
    "    \"USPolitican\":[\n",
    "        \"Trump\",\n",
    "        \"Obama\",\n",
    "        \"Schwarzenegger\",\n",
    "        \"Romney\",\n",
    "        \"Palin\",\n",
    "        \"Clinton\",\n",
    "        \"Biden\",\n",
    "        \"McCain\",\n",
    "        \"Bernie Sanders\",\n",
    "        \"Brian Schatz\",\n",
    "        \"Michael Enzi\",\n",
    "        \"Politic\",\n",
    "        \"Senator\",\n",
    "        \"President\"\n",
    "    ],\n",
    "    \"CarManufacturer\":[\n",
    "        \"Chrysler\",\n",
    "        \"Dodge\",\n",
    "        \"Jeep\",\n",
    "        \"Ford\",\n",
    "        \"Cadillac\",\n",
    "        \"Chevrolet\",\n",
    "        \"Tesla\",\n",
    "        \"Ferrari\",\n",
    "        \"Land Rover\",\n",
    "        \"Porsche\",\n",
    "        \"Volkswagen\",\n",
    "        \"Nissan\",\n",
    "        \"Audi\",\n",
    "        \"BMW\",\n",
    "        \"Toyota\",\n",
    "        \"Car\",\n",
    "        \"V8\",\n",
    "        \"Mustang\",\n",
    "        \"Vehicle\"\n",
    "    ],\n",
    "    \"Soccer\":[\n",
    "        \"Ronaldo\",\n",
    "        \"Champions League\",\n",
    "        \"Neymar\",\n",
    "        \"Özil\",\n",
    "        \"Andrés Iniesta\",\n",
    "        \"Gerard Piqué\",\n",
    "        \"Rooney\",\n",
    "        \"Suarez\",\n",
    "        \"Radamel Falcao\",\n",
    "        \"Gareth Bale\",\n",
    "        \"James Rodríguez\",\n",
    "        \"FC Barcelona\",\n",
    "        \"Real Madrid\",\n",
    "        \"Arsenal\",\n",
    "        \"Chelsea\",\n",
    "        \"Bundesliga\",\n",
    "        \"nba\",\n",
    "        \"nfl\",\n",
    "        \"basketball\",\n",
    "        \"football\",\n",
    "        \"soccer\",\n",
    "        \"tennis\",\n",
    "        \"golf\",\n",
    "        \"rugby\",\n",
    "        \"icehockey\",\n",
    "        \"paintball\",\n",
    "        \"hockey\",\n",
    "        \"Roger Federer\",\n",
    "        \"Tom Brady\"\n",
    "    ]\n",
    "}\n",
    "emoticons = {\n",
    "    \"positive\":\":)\",\n",
    "    \"negative\":\":(\"\n",
    "}\n",
    "\n",
    "twitter_requests = {}\n",
    "for topic in topics:\n",
    "    seed_topics = topics[topic]\n",
    "    for emoticon_text,emoticon_symbol in emoticons.iteritems():\n",
    "        helper_request_key = topic+'_'+emoticon_text\n",
    "        \"\"\"\n",
    "        #################################################################################\n",
    "        Build the search query for the current combination of topic and negative/positive\n",
    "        #################################################################################\n",
    "        \"\"\"\n",
    "        temp_queries = []\n",
    "        for seed_topic in seed_topics:\n",
    "            search_query_parts = []\n",
    "            #just add double quotes\n",
    "            search_query_parts.append('\"'+seed_topic+'\"')\n",
    "            #build list of emoticons based on current positive or negative\n",
    "            search_query_parts.append(emoticon_symbol)\n",
    "            #combine all by joining the parts\n",
    "            search_query = ' '.join(search_query_parts)\n",
    "            #add it to the list of requests which should be performed\n",
    "            temp_queries.append(search_query)\n",
    "        twitter_requests[helper_request_key] = temp_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Perform the real API pulling based on the previously generated requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter_requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-30bae76fef97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/raw'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtweet_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrequest_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrequest_seedtopics\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtwitter_requests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#split they key ('topic_negative') into both parts ['topic','negative'] for further processing and file storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mrequest_key_parts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'twitter_requests' is not defined"
     ]
    }
   ],
   "source": [
    "default_parameters = {\n",
    "    'lang':'en',\n",
    "    'result_type':'recent',\n",
    "    'tweet_mode':'extended', #due to recent twitter changes, tweets with more than 140 characters are allowed\n",
    "    'include_entities':True, #used for replacing content with placeholders\n",
    "    'count':100 # this is the max the API permits\n",
    "}\n",
    "data_dir = 'data/raw'\n",
    "tweet_storage = {}\n",
    "for request_key,request_seedtopics in twitter_requests.items():\n",
    "    #split they key ('topic_negative') into both parts ['topic','negative'] for further processing and file storage\n",
    "    request_key_parts = request_key.split('_')\n",
    "    for seedtopic in request_seedtopics:\n",
    "        #create the filename for the pulled tweets of this execution. name is unique due to current timestamp. => <time>.<ext>\n",
    "        #time stamp will be used for identifying the most recent pulled tweets in subsequent executions\n",
    "        current_file_name = str(int(time.time()))+\"_\"+seedtopic+\".json\"\n",
    "        #joins the complete path => data/<topic>/<positive/negative>/<time>.<ext>\n",
    "        current_file_path = os.path.join(data_dir,request_key_parts[0],request_key_parts[1],current_file_name)\n",
    "        #create the directory if not exists. this is placed at the beginning of the pulling because if an error would occur, it is better to have it at the beginning than at the end of the execution\n",
    "        path = os.path.dirname(current_file_path)\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST and os.path.isdir(path):\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        \"\"\"\n",
    "        #######################################################\n",
    "        2.2.1 Perform requests for the different search queries\n",
    "        #######################################################\n",
    "        \"\"\"\n",
    "        maxTweets = 1000000 #maximum number of tweets for a single script execution, its high to guarantee to receive all tweets within the last 7 days\n",
    "    \n",
    "        tweet_storage = {}\n",
    "        print\n",
    "        print('#'*46)\n",
    "        print(\"Downloading max {0} tweets for {1} | {2}\".format(maxTweets,request_key,seedtopic))\n",
    "        print('#'*46)\n",
    "        for tweet in tweepy.Cursor(api.search,q=seedtopic,**default_parameters).items(maxTweets):\n",
    "            #add tweet to storage\n",
    "            tweet_storage[tweet.id_str] = tweet._json\n",
    "            current_length = len(tweet_storage)\n",
    "            if current_length%100 == 0:\n",
    "                print(\"Downloaded {0} tweets so far\".format(current_length))\n",
    "        print(\"Downloaded {0} tweets\".format(current_length)) \n",
    "        #save tweets to file\n",
    "        with open(current_file_path,'wb') as f:\n",
    "            json.dump(tweet_storage, codecs.getwriter('utf-8')(f), ensure_ascii=False)\n",
    "    \n",
    "        #free memory + empty for next topic\n",
    "        tweet_storage = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

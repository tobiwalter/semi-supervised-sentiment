{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import csv\n",
    "import json\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import codecs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0         int64\n",
      "attitude          object\n",
      "hashtags          object\n",
      "id                 int64\n",
      "processed_text    object\n",
      "raw_text          object\n",
      "seed_topic        object\n",
      "topic             object\n",
      "dtype: object\n",
      "(123457, 8)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/processed/final_dataset.csv\",encoding=\"utf-8\")\n",
    "print(data.dtypes)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "inner_cv = 0\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    global originalclass\n",
    "    global predictedclass\n",
    "    global inner_cv\n",
    "    inner_cv += 1\n",
    "    print(\"CrossVal Iteration\",inner_cv)\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return metrics.accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "def benchmark(clf,name):\n",
    "    global originalclass\n",
    "    global predictedclass\n",
    "    global inner_cv\n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    inner_cv = 0\n",
    "    \n",
    "    cross_validation_k = 10 \n",
    "    print('_' * 80)\n",
    "    print(\"Cross Validating: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    \n",
    "    cross_scores = cross_val_score(clf,X,y,cv=cross_validation_k,scoring=metrics.make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"cross validation scores: %s\" % cross_scores)\n",
    "    train_time = (time() - t0)/cross_validation_k\n",
    "    print(\"time: %0.3fs\" % train_time)\n",
    "\n",
    "    print(metrics.classification_report(originalclass, predictedclass)) \n",
    "    \n",
    "    score = cross_scores.mean()\n",
    "\n",
    "    print(\"accuracy mean:   %0.3f\" % score)\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time\n",
    "\n",
    "y = data[\"attitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X vector n_samples: 123457, n_features: 2207827\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TfidfVectorizer( max_df=1.0,min_df=1,ngram_range=(1,3),tokenizer=tokenize,max_features=50000)\n",
    "X = text_vectorizer.fit_transform(data['processed_text'])\n",
    "print(\"X vector n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Cross Validating: \n",
      "RidgeClassifier(alpha=1.0, class_weight='balanced', copy_X=True,\n",
      "        fit_intercept=True, max_iter=None, normalize=False,\n",
      "        random_state=None, solver='lsqr', tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/linear_model/ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CrossVal Iteration', 1)\n",
      "('CrossVal Iteration', 2)\n",
      "('CrossVal Iteration', 3)\n",
      "cross validation scores: [0.81085219 0.8123056  0.81437111]\n",
      "time: 7.690s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.72      0.69      0.71     40516\n",
      "   positive       0.85      0.87      0.86     82941\n",
      "\n",
      "avg / total       0.81      0.81      0.81    123457\n",
      "\n",
      "accuracy mean:   0.813\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        #(MultinomialNB(alpha=0.2),'MultinomialNB'),\n",
    "        #(BernoulliNB(alpha=0.45),'BernoulliNB'),\n",
    "        #(RidgeClassifier(tol=1e-2, solver=\"lsqr\",class_weight='balanced',normalize=False), \"Ridge Classifier\"),\n",
    "        #(Perceptron(n_iter=33,penalty=None,class_weight='balanced'), \"Perceptron\"),\n",
    "        #(PassiveAggressiveClassifier(n_iter=32,class_weight='balanced',C=1,loss=\"hinge\"), \"Passive-Aggressive\"),\n",
    "        #(KNeighborsClassifier(n_neighbors=20,weights=\"distance\"), \"kNN\"),\n",
    "        #(GradientBoostingClassifier(n_estimators=8),\"GradientBoosting\"),\n",
    "        #(SGDClassifier(alpha=.0001,learning_rate='optimal', n_iter=40,class_weight='balanced',penalty='l2',loss='squared_hinge'),'SGDClassifier'),\n",
    "        (LinearSVC(loss='squared_hinge', penalty='l2',class_weight='balanced',dual=False, tol=1e-3,C=0.5),'LinearSVC'),\n",
    "        #(RandomForestClassifier(class_weight='balanced',criterion='gini',n_estimators=40,max_features='sqrt',min_samples_split=7,min_samples_leaf=3,n_jobs=-1),'RandomForest'),\n",
    "        \n",
    "        ):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Size Influence on Results\n",
    "Testing how the size of the data set influences the overall result.\n",
    "It seems obvious that a bigger dataset results in overall better classification results.\n",
    "Because later on, the individual topics are trained and tested, we need to take the influence of the dataset size into account.\n",
    "On average, each topic only has ca. 15.000 tweets. Thus, the results can not be compared to a model which has taken the full corpus of tweets (ca. 123.000) into account.\n",
    "\n",
    "The total size of the data set will be splitted into 10 linear sizes.\n",
    "For each size, 3 stratified shuffle splits will be evaluated using a 10-Fold cross validation each.\n",
    "Example:\n",
    "Size = 10.000\n",
    "Then, 3 new datasets are generated by a stratified shuffle with the size of 10.000 tweets.\n",
    "Each of the 3 new datasets will be evaluated using 10-Fold Cross Validation.\n",
    "\n",
    "This results in a total of 30 evaluations for each size and an overall evaluation of 300 training and testing steps.\n",
    "For each size, all results are aggregated by mean in order to receive the most accurate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345\n",
      "(12345, 321517)\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.757309, total=   4.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.764754, total=   4.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.783183, total=   5.0s\n",
      "[CV] ................................. , score=0.801373, total=   4.9s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.792841, total=   4.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    9.6s remaining:    9.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.752019, total=   5.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.786542, total=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   10.4s remaining:    4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.774328, total=   5.9s\n",
      "[CV] ................................. , score=0.788692, total=   3.1s\n",
      "[CV] ................................. , score=0.771520, total=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777256054017878\n",
      "(12345, 325362)\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.775563, total=   4.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.762304, total=   5.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.781600, total=   5.3s\n",
      "[CV] ................................. , score=0.772247, total=   5.3s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.800206, total=   5.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    9.9s remaining:    9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.759715, total=   5.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.766389, total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   12.1s remaining:    5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.768103, total=   6.7s\n",
      "[CV] ................................. , score=0.771194, total=   4.8s\n",
      "[CV] ................................. , score=0.788599, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7759239282175623\n",
      "(12345, 323712)\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.783715, total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.778911, total=   6.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.779646, total=   7.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.778054, total=   6.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.793922, total=   4.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   11.0s remaining:   11.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.765993, total=   5.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.773879, total=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   13.5s remaining:    5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.781420, total=   6.5s\n",
      "[CV] ................................. , score=0.788408, total=   4.2s\n",
      "[CV] ................................. , score=0.802674, total=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7781699976344902\n",
      "[{'train_size': 12345, 'accuracy': 0.7781699976344902}]\n"
     ]
    }
   ],
   "source": [
    "def benchmarkTrainSize(model, X, y, n):\n",
    "    train_size = (n / float(len(y)))\n",
    "    scores = []\n",
    "    for train, _ in StratifiedShuffleSplit(y, n_iter=3, train_size=train_size):\n",
    "        text_vectorizer = TfidfVectorizer( max_df=1.0,min_df=1,ngram_range=(1,3),tokenizer=tokenize)\n",
    "        X_train = text_vectorizer.fit_transform(data[\"processed_text\"][train])\n",
    "        print(X_train.shape)\n",
    "        scores.append(cross_val_score(clf,X[train],y[train],cv=10,scoring='f1_weighted',n_jobs=-1,verbose=10).mean())\n",
    "        print(np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "\n",
    "train_size_results = []\n",
    "train_size_steps = 10\n",
    "train_sizes = np.linspace(start=len(y)/train_size_steps,stop=len(y),num=train_size_steps)[:-1]\n",
    "\n",
    "for n in train_sizes[0:1]:\n",
    "    size = int(n)\n",
    "    print(size)\n",
    "    train_size_results.append({'accuracy':benchmarkTrainSize(LinearSVC(loss='squared_hinge', penalty='l2',class_weight='balanced',dual=False, tol=1e-3,C=0.6),X,y,n),'train_size':size})\n",
    "    print(train_size_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Baseline Against Manually Labelled Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attitude           object\n",
      "hashtags           object\n",
      "id                float64\n",
      "processed_text     object\n",
      "raw                object\n",
      "seed_topic         object\n",
      "topic              object\n",
      "manualAttitude     object\n",
      "dtype: object\n",
      "(473, 8)\n"
     ]
    }
   ],
   "source": [
    "manually_labelled = pd.read_csv(\"./data/manually_labelled.csv\",encoding=\"utf-8\")\n",
    "print(manually_labelled.dtypes)\n",
    "print(manually_labelled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize at 0x13f98dc08>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer = TfidfVectorizer( max_df=1.0,min_df=1,ngram_range=(1,3),tokenizer=tokenize)\n",
    "text_vectorizer.fit(data[\"processed_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = text_vectorizer.transform(manually_labelled[\"processed_text\"])\n",
    "y_test = manually_labelled[\"manualAttitude\"]\n",
    "\n",
    "#exclude of tweets from training which should be tested\n",
    "train = data[~data.id.isin(manually_labelled[\"id\"])]\n",
    "\n",
    "X_train = text_vectorizer.transform(train[\"processed_text\"])\n",
    "y_train = train[\"attitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.94      0.76      0.84       256\n",
      "   positive       0.77      0.94      0.84       217\n",
      "\n",
      "avg / total       0.86      0.84      0.84       473\n",
      "\n",
      "0.8414376321353065\n"
     ]
    }
   ],
   "source": [
    "clf_man = LinearSVC(loss='squared_hinge', penalty='l2',class_weight='balanced',dual=False, tol=1e-3,C=0.5)\n",
    "for _ in range(1):\n",
    "    clf.fit(X_train,y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    print(metrics.accuracy_score(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
